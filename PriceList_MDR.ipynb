{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1dsidLuUQ-l"
      },
      "source": [
        "# Multi Digit Number Recognition\n",
        "\n",
        "Original Project https://github.com/ozanpekmezci/capstone/blob/master/multi_digit_recognition.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QUuHcyyF5iq",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Module Imports\n",
        "\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "import random\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from scipy import misc\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_giURzYGjWO",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Setting the random seed so that the results are reproducible. \n",
        "random.seed(42)\n",
        "\n",
        "# Setting variables for MNIST image dimensions\n",
        "mnist_image_height = 28\n",
        "mnist_image_width = 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bI8G9CDQG5xi",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Import MNIST data from keras\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "UK68ofOrHnI1",
        "outputId": "8cf9eb0a-f992-4ac5-b5b4-89eff0de577a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of training dataset: (60000, 28, 28)\n",
            "Shape of test dataset: (10000, 28, 28)\n",
            "Label for image: 5\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Checking the downloaded data\n",
        "print(\"Shape of training dataset: {}\".format(np.shape(X_train)))\n",
        "print(\"Shape of test dataset: {}\".format(np.shape(X_test)))\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(X_train[0], cmap='gray')\n",
        "\n",
        "print(\"Label for image: {}\".format(y_train[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03bKktXm-lRl"
      },
      "source": [
        "## Building a new dataset\n",
        "This method builds a new synthetic dataset that stitches multiple digits together. Labels and data can contain numbers from 0 to 9 including the blank character for shorter house numbers. The length is preset to be always 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOeiOOpLI-P-",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def build_synth_data(data, labels, dataset_size):\n",
        "    \n",
        "    # Define synthetic image dimensions\n",
        "    synth_img_height = 64\n",
        "    synth_img_width = 64\n",
        "    \n",
        "    # Define synthetic data\n",
        "    synth_data = np.ndarray(shape=(dataset_size, synth_img_height,\n",
        "                                   synth_img_width), dtype=np.float32)\n",
        "    \n",
        "    # Define synthetic labels\n",
        "    synth_labels = [] \n",
        "    \n",
        "    # For a loop till the size of the synthetic dataset\n",
        "    for i in range(0,dataset_size):\n",
        "        \n",
        "        # Pick a random number of digits to be in the dataset\n",
        "        num_digits = random.randint(1,5)\n",
        "        \n",
        "        # Randomly sampling indices to extract digits + labels afterwards\n",
        "        s_indices = [random.randint(0, len(data)-1) for p in range(0, num_digits)]\n",
        "        \n",
        "        # stitch images together\n",
        "        new_image = np.hstack([X_train[index] for index in s_indices])\n",
        "        # stitch the labels together\n",
        "        new_label =  [y_train[index] for index in s_indices]\n",
        "        \n",
        "        \n",
        "        # Loop till number of digits - 5, to concatenate blanks images, and blank labels together\n",
        "        for j in range(0,5-num_digits):\n",
        "            new_image = np.hstack([new_image, np.zeros(shape=(mnist_image_height,\n",
        "                                                                   mnist_image_width))])\n",
        "            new_label.append(10) #Might need to remove this step\n",
        "        \n",
        "        # Resize image\n",
        "        new_image =cv2.resize(new_image,(64,64))\n",
        "        \n",
        "        # Assign the image to synth_data\n",
        "        synth_data[i,:,:] = new_image\n",
        "        \n",
        "        # Assign the label to synth_data\n",
        "        synth_labels.append(tuple(new_label))\n",
        "        \n",
        "    \n",
        "    # Return the synthetic dataset\n",
        "    return synth_data,synth_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usRGcxtiJr0N",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Building the training dataset\n",
        "X_synth_train, y_synth_train = build_synth_data(X_train, y_train, 60000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLNhglO0J1Xk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Building the test dataset\n",
        "X_synth_test, y_synth_test = build_synth_data(X_test, y_test, 10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOQpSYQNHKIu"
      },
      "source": [
        "## Convert Labels\n",
        "This function converts each digit label to one-hot array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slWvJtn2Kts1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Converting labels to One-hot representations of shape (set_size, digits, classes)\n",
        "possible_classes = 11\n",
        "\n",
        "def convert_labels(labels):\n",
        "    \n",
        "    # As per Keras conventions, the multiple labels need to be of the form [array_digit1,...5]\n",
        "    # Each digit array will be of shape (60000,11)\n",
        "        \n",
        "    # Declare output ndarrays\n",
        "    # 5 for digits, 11 for possible classes  \n",
        "    dig0_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    dig1_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    dig2_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    dig3_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    dig4_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    \n",
        "    for index,label in enumerate(labels):\n",
        "        \n",
        "        # Using np_utils from keras to OHE the labels in the image\n",
        "        dig0_arr[index,:] = np_utils.to_categorical(label[0],possible_classes)\n",
        "        dig1_arr[index,:] = np_utils.to_categorical(label[1],possible_classes)\n",
        "        dig2_arr[index,:] = np_utils.to_categorical(label[2],possible_classes)\n",
        "        dig3_arr[index,:] = np_utils.to_categorical(label[3],possible_classes)\n",
        "        dig4_arr[index,:] = np_utils.to_categorical(label[4],possible_classes)\n",
        "        \n",
        "    return [dig0_arr,dig1_arr,dig2_arr,dig3_arr,dig4_arr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17m-itv9Lizo",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train_labels = convert_labels(y_synth_train)\n",
        "test_labels = convert_labels(y_synth_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe8PQKllIT2N"
      },
      "source": [
        "## Prepare Data for Keras\n",
        "Reshape image data to be processed by Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTQg2PaWLzc0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def prep_data_keras(img_data):\n",
        "    \n",
        "    # Reshaping data for keras, with tensorflow as backend\n",
        "    img_data = img_data.reshape(len(img_data), 64, 64, 1)\n",
        "    \n",
        "    # Converting everything to floats\n",
        "    img_data = img_data.astype('float32')\n",
        "    \n",
        "    # Normalizing values between 0 and 1\n",
        "    img_data /= 255\n",
        "    \n",
        "    return img_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHUhGAErL--5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train_images = prep_data_keras(X_synth_train)\n",
        "test_images = prep_data_keras(X_synth_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INF-j_J_MTi_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Importing relevant keras modules\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj66iuNtLfJu"
      },
      "source": [
        "## Build Model\n",
        "Build Deep Learning model to process data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixTneFcAM_BN",
        "outputId": "1a92a0e3-efb3-4ba0-c141-0fd8cda8841c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "469/469 [==============================] - 32s 65ms/step - loss: 3.6486 - dense_7_loss: 0.9279 - dense_8_loss: 0.8801 - dense_9_loss: 0.7715 - dense_10_loss: 0.6507 - dense_11_loss: 0.4184 - dense_7_accuracy: 0.6865 - dense_8_accuracy: 0.7090 - dense_9_accuracy: 0.7478 - dense_10_accuracy: 0.7928 - dense_11_accuracy: 0.8705 - val_loss: 1.0306 - val_dense_7_loss: 0.2449 - val_dense_8_loss: 0.2294 - val_dense_9_loss: 0.2227 - val_dense_10_loss: 0.1732 - val_dense_11_loss: 0.1604 - val_dense_7_accuracy: 0.9395 - val_dense_8_accuracy: 0.9413 - val_dense_9_accuracy: 0.9489 - val_dense_10_accuracy: 0.9617 - val_dense_11_accuracy: 0.9556\n",
            "Epoch 2/15\n",
            "469/469 [==============================] - 29s 61ms/step - loss: 2.2950 - dense_7_loss: 0.5614 - dense_8_loss: 0.5348 - dense_9_loss: 0.4969 - dense_10_loss: 0.4155 - dense_11_loss: 0.2864 - dense_7_accuracy: 0.8126 - dense_8_accuracy: 0.8215 - dense_9_accuracy: 0.8343 - dense_10_accuracy: 0.8627 - dense_11_accuracy: 0.9059 - val_loss: 0.7348 - val_dense_7_loss: 0.1722 - val_dense_8_loss: 0.1604 - val_dense_9_loss: 0.1610 - val_dense_10_loss: 0.1288 - val_dense_11_loss: 0.1124 - val_dense_7_accuracy: 0.9601 - val_dense_8_accuracy: 0.9652 - val_dense_9_accuracy: 0.9645 - val_dense_10_accuracy: 0.9742 - val_dense_11_accuracy: 0.9755\n",
            "Epoch 3/15\n",
            "469/469 [==============================] - 29s 62ms/step - loss: 1.9604 - dense_7_loss: 0.4723 - dense_8_loss: 0.4539 - dense_9_loss: 0.4301 - dense_10_loss: 0.3567 - dense_11_loss: 0.2474 - dense_7_accuracy: 0.8422 - dense_8_accuracy: 0.8471 - dense_9_accuracy: 0.8561 - dense_10_accuracy: 0.8807 - dense_11_accuracy: 0.9184 - val_loss: 0.5829 - val_dense_7_loss: 0.1366 - val_dense_8_loss: 0.1286 - val_dense_9_loss: 0.1265 - val_dense_10_loss: 0.0969 - val_dense_11_loss: 0.0942 - val_dense_7_accuracy: 0.9663 - val_dense_8_accuracy: 0.9710 - val_dense_9_accuracy: 0.9721 - val_dense_10_accuracy: 0.9816 - val_dense_11_accuracy: 0.9798\n",
            "Epoch 4/15\n",
            "469/469 [==============================] - 28s 61ms/step - loss: 1.7495 - dense_7_loss: 0.4145 - dense_8_loss: 0.3974 - dense_9_loss: 0.3864 - dense_10_loss: 0.3228 - dense_11_loss: 0.2284 - dense_7_accuracy: 0.8611 - dense_8_accuracy: 0.8669 - dense_9_accuracy: 0.8698 - dense_10_accuracy: 0.8906 - dense_11_accuracy: 0.9225 - val_loss: 0.5162 - val_dense_7_loss: 0.1190 - val_dense_8_loss: 0.1066 - val_dense_9_loss: 0.1120 - val_dense_10_loss: 0.0840 - val_dense_11_loss: 0.0946 - val_dense_7_accuracy: 0.9684 - val_dense_8_accuracy: 0.9743 - val_dense_9_accuracy: 0.9740 - val_dense_10_accuracy: 0.9808 - val_dense_11_accuracy: 0.9758\n",
            "Epoch 5/15\n",
            "469/469 [==============================] - 28s 61ms/step - loss: 1.5900 - dense_7_loss: 0.3712 - dense_8_loss: 0.3605 - dense_9_loss: 0.3493 - dense_10_loss: 0.2941 - dense_11_loss: 0.2149 - dense_7_accuracy: 0.8742 - dense_8_accuracy: 0.8777 - dense_9_accuracy: 0.8805 - dense_10_accuracy: 0.8997 - dense_11_accuracy: 0.9264 - val_loss: 0.4366 - val_dense_7_loss: 0.1025 - val_dense_8_loss: 0.0925 - val_dense_9_loss: 0.0983 - val_dense_10_loss: 0.0694 - val_dense_11_loss: 0.0740 - val_dense_7_accuracy: 0.9723 - val_dense_8_accuracy: 0.9760 - val_dense_9_accuracy: 0.9757 - val_dense_10_accuracy: 0.9820 - val_dense_11_accuracy: 0.9810\n",
            "Epoch 6/15\n",
            "469/469 [==============================] - 29s 61ms/step - loss: 1.4579 - dense_7_loss: 0.3383 - dense_8_loss: 0.3262 - dense_9_loss: 0.3234 - dense_10_loss: 0.2744 - dense_11_loss: 0.1955 - dense_7_accuracy: 0.8843 - dense_8_accuracy: 0.8887 - dense_9_accuracy: 0.8899 - dense_10_accuracy: 0.9054 - dense_11_accuracy: 0.9326 - val_loss: 0.4142 - val_dense_7_loss: 0.0952 - val_dense_8_loss: 0.0880 - val_dense_9_loss: 0.0942 - val_dense_10_loss: 0.0654 - val_dense_11_loss: 0.0713 - val_dense_7_accuracy: 0.9758 - val_dense_8_accuracy: 0.9771 - val_dense_9_accuracy: 0.9771 - val_dense_10_accuracy: 0.9846 - val_dense_11_accuracy: 0.9834\n",
            "Epoch 7/15\n",
            "469/469 [==============================] - 29s 62ms/step - loss: 1.3372 - dense_7_loss: 0.3077 - dense_8_loss: 0.2991 - dense_9_loss: 0.2926 - dense_10_loss: 0.2508 - dense_11_loss: 0.1870 - dense_7_accuracy: 0.8949 - dense_8_accuracy: 0.8971 - dense_9_accuracy: 0.8983 - dense_10_accuracy: 0.9128 - dense_11_accuracy: 0.9349 - val_loss: 0.3756 - val_dense_7_loss: 0.0876 - val_dense_8_loss: 0.0783 - val_dense_9_loss: 0.0875 - val_dense_10_loss: 0.0568 - val_dense_11_loss: 0.0654 - val_dense_7_accuracy: 0.9753 - val_dense_8_accuracy: 0.9785 - val_dense_9_accuracy: 0.9765 - val_dense_10_accuracy: 0.9859 - val_dense_11_accuracy: 0.9835\n",
            "Epoch 8/15\n",
            "469/469 [==============================] - 29s 62ms/step - loss: 1.2542 - dense_7_loss: 0.2892 - dense_8_loss: 0.2774 - dense_9_loss: 0.2743 - dense_10_loss: 0.2368 - dense_11_loss: 0.1765 - dense_7_accuracy: 0.8994 - dense_8_accuracy: 0.9032 - dense_9_accuracy: 0.9035 - dense_10_accuracy: 0.9157 - dense_11_accuracy: 0.9376 - val_loss: 0.3646 - val_dense_7_loss: 0.0856 - val_dense_8_loss: 0.0753 - val_dense_9_loss: 0.0815 - val_dense_10_loss: 0.0540 - val_dense_11_loss: 0.0681 - val_dense_7_accuracy: 0.9753 - val_dense_8_accuracy: 0.9794 - val_dense_9_accuracy: 0.9789 - val_dense_10_accuracy: 0.9863 - val_dense_11_accuracy: 0.9828\n",
            "Epoch 9/15\n",
            "469/469 [==============================] - 29s 62ms/step - loss: 1.1696 - dense_7_loss: 0.2702 - dense_8_loss: 0.2573 - dense_9_loss: 0.2557 - dense_10_loss: 0.2212 - dense_11_loss: 0.1653 - dense_7_accuracy: 0.9059 - dense_8_accuracy: 0.9093 - dense_9_accuracy: 0.9085 - dense_10_accuracy: 0.9221 - dense_11_accuracy: 0.9412 - val_loss: 0.3445 - val_dense_7_loss: 0.0795 - val_dense_8_loss: 0.0707 - val_dense_9_loss: 0.0805 - val_dense_10_loss: 0.0539 - val_dense_11_loss: 0.0600 - val_dense_7_accuracy: 0.9788 - val_dense_8_accuracy: 0.9804 - val_dense_9_accuracy: 0.9770 - val_dense_10_accuracy: 0.9861 - val_dense_11_accuracy: 0.9849\n",
            "Epoch 10/15\n",
            "469/469 [==============================] - 30s 64ms/step - loss: 1.1089 - dense_7_loss: 0.2549 - dense_8_loss: 0.2443 - dense_9_loss: 0.2397 - dense_10_loss: 0.2102 - dense_11_loss: 0.1597 - dense_7_accuracy: 0.9085 - dense_8_accuracy: 0.9130 - dense_9_accuracy: 0.9135 - dense_10_accuracy: 0.9245 - dense_11_accuracy: 0.9438 - val_loss: 0.3221 - val_dense_7_loss: 0.0756 - val_dense_8_loss: 0.0653 - val_dense_9_loss: 0.0738 - val_dense_10_loss: 0.0458 - val_dense_11_loss: 0.0616 - val_dense_7_accuracy: 0.9785 - val_dense_8_accuracy: 0.9812 - val_dense_9_accuracy: 0.9800 - val_dense_10_accuracy: 0.9883 - val_dense_11_accuracy: 0.9849\n",
            "Epoch 11/15\n",
            "469/469 [==============================] - 30s 64ms/step - loss: 1.0536 - dense_7_loss: 0.2386 - dense_8_loss: 0.2353 - dense_9_loss: 0.2245 - dense_10_loss: 0.2016 - dense_11_loss: 0.1536 - dense_7_accuracy: 0.9155 - dense_8_accuracy: 0.9147 - dense_9_accuracy: 0.9198 - dense_10_accuracy: 0.9275 - dense_11_accuracy: 0.9444 - val_loss: 0.3170 - val_dense_7_loss: 0.0682 - val_dense_8_loss: 0.0664 - val_dense_9_loss: 0.0754 - val_dense_10_loss: 0.0466 - val_dense_11_loss: 0.0603 - val_dense_7_accuracy: 0.9805 - val_dense_8_accuracy: 0.9817 - val_dense_9_accuracy: 0.9799 - val_dense_10_accuracy: 0.9872 - val_dense_11_accuracy: 0.9860\n",
            "Epoch 12/15\n",
            "469/469 [==============================] - 29s 62ms/step - loss: 0.9971 - dense_7_loss: 0.2267 - dense_8_loss: 0.2219 - dense_9_loss: 0.2158 - dense_10_loss: 0.1919 - dense_11_loss: 0.1408 - dense_7_accuracy: 0.9189 - dense_8_accuracy: 0.9194 - dense_9_accuracy: 0.9211 - dense_10_accuracy: 0.9301 - dense_11_accuracy: 0.9491 - val_loss: 0.3116 - val_dense_7_loss: 0.0665 - val_dense_8_loss: 0.0619 - val_dense_9_loss: 0.0721 - val_dense_10_loss: 0.0458 - val_dense_11_loss: 0.0653 - val_dense_7_accuracy: 0.9802 - val_dense_8_accuracy: 0.9828 - val_dense_9_accuracy: 0.9796 - val_dense_10_accuracy: 0.9878 - val_dense_11_accuracy: 0.9840\n",
            "Epoch 13/15\n",
            "469/469 [==============================] - 29s 63ms/step - loss: 0.9491 - dense_7_loss: 0.2196 - dense_8_loss: 0.2096 - dense_9_loss: 0.2015 - dense_10_loss: 0.1815 - dense_11_loss: 0.1369 - dense_7_accuracy: 0.9207 - dense_8_accuracy: 0.9244 - dense_9_accuracy: 0.9281 - dense_10_accuracy: 0.9335 - dense_11_accuracy: 0.9510 - val_loss: 0.3090 - val_dense_7_loss: 0.0677 - val_dense_8_loss: 0.0614 - val_dense_9_loss: 0.0712 - val_dense_10_loss: 0.0462 - val_dense_11_loss: 0.0625 - val_dense_7_accuracy: 0.9807 - val_dense_8_accuracy: 0.9828 - val_dense_9_accuracy: 0.9812 - val_dense_10_accuracy: 0.9876 - val_dense_11_accuracy: 0.9855\n",
            "Epoch 14/15\n",
            "469/469 [==============================] - 29s 63ms/step - loss: 0.9214 - dense_7_loss: 0.2112 - dense_8_loss: 0.2054 - dense_9_loss: 0.1974 - dense_10_loss: 0.1768 - dense_11_loss: 0.1306 - dense_7_accuracy: 0.9228 - dense_8_accuracy: 0.9248 - dense_9_accuracy: 0.9274 - dense_10_accuracy: 0.9360 - dense_11_accuracy: 0.9526 - val_loss: 0.2945 - val_dense_7_loss: 0.0642 - val_dense_8_loss: 0.0579 - val_dense_9_loss: 0.0726 - val_dense_10_loss: 0.0402 - val_dense_11_loss: 0.0596 - val_dense_7_accuracy: 0.9815 - val_dense_8_accuracy: 0.9830 - val_dense_9_accuracy: 0.9811 - val_dense_10_accuracy: 0.9898 - val_dense_11_accuracy: 0.9865\n",
            "Epoch 15/15\n",
            "469/469 [==============================] - 29s 62ms/step - loss: 0.8860 - dense_7_loss: 0.2007 - dense_8_loss: 0.1961 - dense_9_loss: 0.1894 - dense_10_loss: 0.1742 - dense_11_loss: 0.1256 - dense_7_accuracy: 0.9259 - dense_8_accuracy: 0.9273 - dense_9_accuracy: 0.9294 - dense_10_accuracy: 0.9358 - dense_11_accuracy: 0.9540 - val_loss: 0.2878 - val_dense_7_loss: 0.0660 - val_dense_8_loss: 0.0557 - val_dense_9_loss: 0.0706 - val_dense_10_loss: 0.0404 - val_dense_11_loss: 0.0550 - val_dense_7_accuracy: 0.9812 - val_dense_8_accuracy: 0.9849 - val_dense_9_accuracy: 0.9810 - val_dense_10_accuracy: 0.9889 - val_dense_11_accuracy: 0.9868\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f03382cf090>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Building the model\n",
        "\n",
        "batch_size = 128\n",
        "nb_classes = 11\n",
        "nb_epoch = 15\n",
        "\n",
        "# image input dimensions\n",
        "img_rows = 64\n",
        "img_cols = 64\n",
        "img_channels = 1\n",
        "\n",
        "# number of convulation filters to use\n",
        "nb_filters = 32\n",
        "# size of pooling area for max pooling\n",
        "pool_size = (2, 2)\n",
        "# convolution kernel size\n",
        "kernel_size = (3, 3)\n",
        "\n",
        "# defining the input\n",
        "inputs = Input(shape=(img_rows, img_cols, img_channels))\n",
        "\n",
        "# Model taken from keras example.\n",
        "cov = Conv2D(nb_filters, kernel_size=kernel_size, padding='same')(inputs)\n",
        "cov = Activation('relu')(cov)\n",
        "cov = Conv2D(nb_filters, kernel_size=kernel_size, padding='same')(cov)\n",
        "cov = Activation('relu')(cov)\n",
        "cov = MaxPooling2D(pool_size=pool_size)(cov)\n",
        "cov = Dropout(0.25)(cov)\n",
        "cov_out = Flatten()(cov)\n",
        "\n",
        "\n",
        "# Dense Layers\n",
        "cov2 = Dense(128, activation='relu')(cov_out)\n",
        "cov2 = Dropout(0.5)(cov2)\n",
        "\n",
        "\n",
        "\n",
        "# Prediction layers\n",
        "c0 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "c1 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "c2 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "c3 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "c4 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "\n",
        "# Defining the model\n",
        "model = Model(inputs=inputs,outputs=[c0,c1,c2,c3,c4])\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "# Fitting the model\n",
        "model.fit(train_images,train_labels,batch_size=batch_size,epochs=nb_epoch,verbose=1,\n",
        "          validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1gl0EeoPo6k",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8gkvmbWLoY1"
      },
      "source": [
        "## Calculate Accuracy\n",
        "Custom accuracy calculation for individual digits and the whole sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI7q72qiR49W",
        "outputId": "29c5e1ea-4d82-4c2b-ebfb-d66da8c55ac1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actual labels: [9, 6, 9, 10, 10]\n",
            "Predicted labels: [9, 6, 9, 10, 10]\n",
            "\n",
            "Actual labels: [6, 8, 1, 0, 2]\n",
            "Predicted labels: [6, 8, 1, 0, 2]\n",
            "\n",
            "Actual labels: [2, 7, 0, 0, 8]\n",
            "Predicted labels: [2, 7, 0, 0, 8]\n",
            "\n",
            "Actual labels: [0, 0, 7, 4, 10]\n",
            "Predicted labels: [0, 0, 7, 4, 10]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Printing some examples of real and predicted labels\n",
        "for i in random.sample(range(0,4),4):\n",
        "    \n",
        "    actual_labels = []\n",
        "    predicted_labels = []\n",
        "    \n",
        "    for j in range(0,5):\n",
        "        actual_labels.append(np.argmax(test_labels[j][i]))\n",
        "        predicted_labels.append(np.argmax(predictions[j][i]))\n",
        "        \n",
        "    print(\"Actual labels: {}\".format(actual_labels))\n",
        "    print(\"Predicted labels: {}\\n\".format(predicted_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BAwhIZqSZG8"
      },
      "source": [
        "Source: https://sajalsharma.com/portfolio/digit_sequence_recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-5mbhORBJNm"
      },
      "source": [
        "## Deploy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyiulBuItGz4",
        "outputId": "704b0f4f-e807-43a5-db5b-c2c1153d8c8d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtxC8_lL47Hu",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "MODEL_DIR = tempfile.gettempdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RopFtABk8Jwt",
        "outputId": "4ebf03a0-4c76-4948-e70e-d86aa59ee2fa",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/tmp'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDUnklYOLEre",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "version = 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3BFgjZZLF1d",
        "outputId": "c31b0072-d358-49ea-8733-37bbb516abc0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "export_path = /tmp/1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's join the temp model directory with our chosen version number \n",
        "# The expected result will be = '\\tmp\\version number'\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "print('export_path = {}\\n'.format(export_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8eTxHjBLIfc",
        "outputId": "780009ab-594e-4f01-c834-5ab4f9c50d58",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n"
          ]
        }
      ],
      "source": [
        "# Let's save the model using simple_save\n",
        "# If the directory already exists, we will remove it using '!rm' \n",
        "# rm removes each file specified on the command line. \n",
        "\n",
        "if os.path.isdir(export_path):\n",
        "  print('\\nAlready saved a model, cleaning up\\n')\n",
        "  !rm -r {export_path}\n",
        "\n",
        "model.save(\n",
        "    export_path,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9Ra026TLWhb",
        "outputId": "33ff75ae-91d7-47b3-c030-99ca016b0dc8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 296\n",
            "drwxr-xr-x 2 root root   4096 Apr 25 19:22 assets\n",
            "-rw-r--r-- 1 root root  30105 Apr 25 19:22 keras_metadata.pb\n",
            "-rw-r--r-- 1 root root 259561 Apr 25 19:22 saved_model.pb\n",
            "drwxr-xr-x 2 root root   4096 Apr 25 19:22 variables\n"
          ]
        }
      ],
      "source": [
        "!ls -l {export_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb9qG73HLg93",
        "outputId": "b672a915-35ba-4e68-dd23-fb650faf8e12",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['input_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 64, 64, 1)\n",
            "        name: serving_default_input_2:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_10'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 11)\n",
            "        name: StatefulPartitionedCall:0\n",
            "    outputs['dense_11'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 11)\n",
            "        name: StatefulPartitionedCall:1\n",
            "    outputs['dense_7'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 11)\n",
            "        name: StatefulPartitionedCall:2\n",
            "    outputs['dense_8'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 11)\n",
            "        name: StatefulPartitionedCall:3\n",
            "    outputs['dense_9'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 11)\n",
            "        name: StatefulPartitionedCall:4\n",
            "  Method name is: tensorflow/serving/predict\n",
            "\n",
            "Concrete Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='input_2')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        }
      ],
      "source": [
        "# Now we can view our saved model\n",
        "!saved_model_cli show --dir {export_path} --all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY2-ep-pLsse",
        "outputId": "993fbe8f-1c80-43c5-afc9-9d62a0e87252",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2943  100  2943    0     0  60061      0 --:--:-- --:--:-- --:--:-- 58860\n",
            "OK\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:12 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [349 B]\n",
            "Get:13 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [341 B]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,272 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,167 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [942 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,949 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [909 kB]\n",
            "Get:24 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,732 kB]\n",
            "Get:25 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,496 kB]\n",
            "Get:26 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [999 kB]\n",
            "Get:27 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 14.8 MB in 4s (3,357 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "56 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ],
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX71bSEuLyak",
        "outputId": "c1b9b215-a08d-4992-ef88-30f471f9afc5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 56 not upgraded.\n",
            "Need to get 340 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.8.0 [340 MB]\n",
            "Fetched 340 MB in 7s (50.6 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 155501 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.8.0_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.8.0) ...\n",
            "Setting up tensorflow-model-server (2.8.0) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install tensorflow-model-server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGoe5nMEL3k8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMIOAJodL8pQ",
        "outputId": "388f4275-00aa-4d58-ed68-7b62c057dceb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ]
        }
      ],
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=fashion_model \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ltm3oB3L_J1",
        "outputId": "b49ea166-0406-4be0-f60e-f6d6f54d1ff5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n"
          ]
        }
      ],
      "source": [
        "!tail server.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWho2dRTMAwc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def show(idx, title):\n",
        "  plt.figure()\n",
        "  plt.imshow(X_test[idx].reshape(64,64))\n",
        "  plt.title('\\n\\n{}'.format(title), fontdict={'size': 16})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "y-kA7UOPMIUX",
        "outputId": "17aa4782-647e-47d5-b8e6-3644077c116d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-428bd40d329d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrando\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrando\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'An Example Image: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrando\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-63-1baee20ea6b8>\u001b[0m in \u001b[0;36mshow\u001b[0;34m(idx, title)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (64,64)"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rando = random.randint(0,len(X_test)-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "av6aKl1xMIZQ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "PriceList_MDR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
