{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PriceList_MDR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aldwin-b/PriceList/blob/main/PriceList_MDR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "I1dsidLuUQ-l"
      },
      "cell_type": "markdown",
      "source": [
        "# Multi Digit Number Recognition\n",
        "\n",
        "Original Project https://github.com/ozanpekmezci/capstone/blob/master/multi_digit_recognition.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "_QUuHcyyF5iq"
      },
      "cell_type": "code",
      "source": [
        "# Module Imports\n",
        "\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "import random\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from scipy import misc\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_giURzYGjWO"
      },
      "cell_type": "code",
      "source": [
        "# Setting the random seed so that the results are reproducible. \n",
        "random.seed(42)\n",
        "\n",
        "# Setting variables for MNIST image dimensions\n",
        "mnist_image_height = 28\n",
        "mnist_image_width = 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bI8G9CDQG5xi"
      },
      "cell_type": "code",
      "source": [
        "# Import MNIST data from keras\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UK68ofOrHnI1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "8cf9eb0a-f992-4ac5-b5b4-89eff0de577a"
      },
      "cell_type": "code",
      "source": [
        "#Checking the downloaded data\n",
        "print(\"Shape of training dataset: {}\".format(np.shape(X_train)))\n",
        "print(\"Shape of test dataset: {}\".format(np.shape(X_test)))\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(X_train[0], cmap='gray')\n",
        "\n",
        "print(\"Label for image: {}\".format(y_train[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training dataset: (60000, 28, 28)\n",
            "Shape of test dataset: (10000, 28, 28)\n",
            "Label for image: 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "03bKktXm-lRl"
      },
      "cell_type": "markdown",
      "source": [
        "## Building a new dataset\n",
        "This method builds a new synthetic dataset that stitches multiple digits together. Labels and data can contain numbers from 0 to 9 including the blank character for shorter house numbers. The length is preset to be always 5."
      ]
    },
    {
      "metadata": {
        "id": "yOeiOOpLI-P-"
      },
      "cell_type": "code",
      "source": [
        "def build_synth_data(data, labels, dataset_size):\n",
        "    \n",
        "    # Define synthetic image dimensions\n",
        "    synth_img_height = 64\n",
        "    synth_img_width = 64\n",
        "    \n",
        "    # Define synthetic data\n",
        "    synth_data = np.ndarray(shape=(dataset_size, synth_img_height,\n",
        "                                   synth_img_width), dtype=np.float32)\n",
        "    \n",
        "    # Define synthetic labels\n",
        "    synth_labels = [] \n",
        "    \n",
        "    # For a loop till the size of the synthetic dataset\n",
        "    for i in range(0,dataset_size):\n",
        "        \n",
        "        # Pick a random number of digits to be in the dataset\n",
        "        num_digits = random.randint(1,5)\n",
        "        \n",
        "        # Randomly sampling indices to extract digits + labels afterwards\n",
        "        s_indices = [random.randint(0, len(data)-1) for p in range(0, num_digits)]\n",
        "        \n",
        "        # stitch images together\n",
        "        new_image = np.hstack([X_train[index] for index in s_indices])\n",
        "        # stitch the labels together\n",
        "        new_label =  [y_train[index] for index in s_indices]\n",
        "        \n",
        "        \n",
        "        # Loop till number of digits - 5, to concatenate blanks images, and blank labels together\n",
        "        for j in range(0,5-num_digits):\n",
        "            new_image = np.hstack([new_image, np.zeros(shape=(mnist_image_height,\n",
        "                                                                   mnist_image_width))])\n",
        "            new_label.append(10) #Might need to remove this step\n",
        "        \n",
        "        # Resize image\n",
        "        new_image =cv2.resize(new_image,(64,64))\n",
        "        \n",
        "        # Assign the image to synth_data\n",
        "        synth_data[i,:,:] = new_image\n",
        "        \n",
        "        # Assign the label to synth_data\n",
        "        synth_labels.append(tuple(new_label))\n",
        "        \n",
        "    \n",
        "    # Return the synthetic dataset\n",
        "    return synth_data,synth_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "usRGcxtiJr0N"
      },
      "cell_type": "code",
      "source": [
        "# Building the training dataset\n",
        "X_synth_train, y_synth_train = build_synth_data(X_train, y_train, 60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dLNhglO0J1Xk"
      },
      "cell_type": "code",
      "source": [
        "# Building the test dataset\n",
        "X_synth_test, y_synth_test = build_synth_data(X_test, y_test, 10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xOQpSYQNHKIu"
      },
      "cell_type": "markdown",
      "source": [
        "## Convert Labels\n",
        "This function converts each digit label to one-hot array."
      ]
    },
    {
      "metadata": {
        "id": "slWvJtn2Kts1"
      },
      "cell_type": "code",
      "source": [
        "# Converting labels to One-hot representations of shape (set_size, digits, classes)\n",
        "possible_classes = 11\n",
        "\n",
        "def convert_labels(labels):\n",
        "    \n",
        "    # As per Keras conventions, the multiple labels need to be of the form [array_digit1,...5]\n",
        "    # Each digit array will be of shape (60000,11)\n",
        "        \n",
        "    # Declare output ndarrays\n",
        "    # 5 for digits, 11 for possible classes  \n",
        "    dig0_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    dig1_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    dig2_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    dig3_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    dig4_arr = np.ndarray(shape=(len(labels),possible_classes))\n",
        "    \n",
        "    for index,label in enumerate(labels):\n",
        "        \n",
        "        # Using np_utils from keras to OHE the labels in the image\n",
        "        dig0_arr[index,:] = np_utils.to_categorical(label[0],possible_classes)\n",
        "        dig1_arr[index,:] = np_utils.to_categorical(label[1],possible_classes)\n",
        "        dig2_arr[index,:] = np_utils.to_categorical(label[2],possible_classes)\n",
        "        dig3_arr[index,:] = np_utils.to_categorical(label[3],possible_classes)\n",
        "        dig4_arr[index,:] = np_utils.to_categorical(label[4],possible_classes)\n",
        "        \n",
        "    return [dig0_arr,dig1_arr,dig2_arr,dig3_arr,dig4_arr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "17m-itv9Lizo"
      },
      "cell_type": "code",
      "source": [
        "train_labels = convert_labels(y_synth_train)\n",
        "test_labels = convert_labels(y_synth_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oe8PQKllIT2N"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Data for Keras\n",
        "Reshape image data to be processed by Keras."
      ]
    },
    {
      "metadata": {
        "id": "WTQg2PaWLzc0"
      },
      "cell_type": "code",
      "source": [
        "def prep_data_keras(img_data):\n",
        "    \n",
        "    # Reshaping data for keras, with tensorflow as backend\n",
        "    img_data = img_data.reshape(len(img_data), 64, 64, 1)\n",
        "    \n",
        "    # Converting everything to floats\n",
        "    img_data = img_data.astype('float32')\n",
        "    \n",
        "    # Normalizing values between 0 and 1\n",
        "    img_data /= 255\n",
        "    \n",
        "    return img_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GHUhGAErL--5"
      },
      "cell_type": "code",
      "source": [
        "train_images = prep_data_keras(X_synth_train)\n",
        "test_images = prep_data_keras(X_synth_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "INF-j_J_MTi_"
      },
      "cell_type": "code",
      "source": [
        "# Importing relevant keras modules\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sj66iuNtLfJu"
      },
      "cell_type": "markdown",
      "source": [
        "## Build Model\n",
        "Build Deep Learning model to process data."
      ]
    },
    {
      "metadata": {
        "id": "ixTneFcAM_BN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a92a0e3-efb3-4ba0-c141-0fd8cda8841c"
      },
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "\n",
        "batch_size = 128\n",
        "nb_classes = 11\n",
        "nb_epoch = 15\n",
        "\n",
        "# image input dimensions\n",
        "img_rows = 64\n",
        "img_cols = 64\n",
        "img_channels = 1\n",
        "\n",
        "# number of convulation filters to use\n",
        "nb_filters = 32\n",
        "# size of pooling area for max pooling\n",
        "pool_size = (2, 2)\n",
        "# convolution kernel size\n",
        "kernel_size = (3, 3)\n",
        "\n",
        "# defining the input\n",
        "inputs = Input(shape=(img_rows, img_cols, img_channels))\n",
        "\n",
        "# Model taken from keras example.\n",
        "cov = Conv2D(nb_filters, kernel_size=kernel_size, padding='same')(inputs)\n",
        "cov = Activation('relu')(cov)\n",
        "cov = Conv2D(nb_filters, kernel_size=kernel_size, padding='same')(cov)\n",
        "cov = Activation('relu')(cov)\n",
        "cov = MaxPooling2D(pool_size=pool_size)(cov)\n",
        "cov = Dropout(0.25)(cov)\n",
        "cov_out = Flatten()(cov)\n",
        "\n",
        "\n",
        "# Dense Layers\n",
        "cov2 = Dense(128, activation='relu')(cov_out)\n",
        "cov2 = Dropout(0.5)(cov2)\n",
        "\n",
        "\n",
        "\n",
        "# Prediction layers\n",
        "c0 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "c1 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "c2 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "c3 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "c4 = Dense(nb_classes, activation='softmax')(cov2)\n",
        "\n",
        "# Defining the model\n",
        "model = Model(inputs=inputs,outputs=[c0,c1,c2,c3,c4])\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "# Fitting the model\n",
        "model.fit(train_images,train_labels,batch_size=batch_size,epochs=nb_epoch,verbose=1,\n",
        "          validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "469/469 [==============================] - 32s 65ms/step - loss: 3.6486 - dense_7_loss: 0.9279 - dense_8_loss: 0.8801 - dense_9_loss: 0.7715 - dense_10_loss: 0.6507 - dense_11_loss: 0.4184 - dense_7_accuracy: 0.6865 - dense_8_accuracy: 0.7090 - dense_9_accuracy: 0.7478 - dense_10_accuracy: 0.7928 - dense_11_accuracy: 0.8705 - val_loss: 1.0306 - val_dense_7_loss: 0.2449 - val_dense_8_loss: 0.2294 - val_dense_9_loss: 0.2227 - val_dense_10_loss: 0.1732 - val_dense_11_loss: 0.1604 - val_dense_7_accuracy: 0.9395 - val_dense_8_accuracy: 0.9413 - val_dense_9_accuracy: 0.9489 - val_dense_10_accuracy: 0.9617 - val_dense_11_accuracy: 0.9556\n",
            "Epoch 2/15\n",
            "469/469 [==============================] - 29s 61ms/step - loss: 2.2950 - dense_7_loss: 0.5614 - dense_8_loss: 0.5348 - dense_9_loss: 0.4969 - dense_10_loss: 0.4155 - dense_11_loss: 0.2864 - dense_7_accuracy: 0.8126 - dense_8_accuracy: 0.8215 - dense_9_accuracy: 0.8343 - dense_10_accuracy: 0.8627 - dense_11_accuracy: 0.9059 - val_loss: 0.7348 - val_dense_7_loss: 0.1722 - val_dense_8_loss: 0.1604 - val_dense_9_loss: 0.1610 - val_dense_10_loss: 0.1288 - val_dense_11_loss: 0.1124 - val_dense_7_accuracy: 0.9601 - val_dense_8_accuracy: 0.9652 - val_dense_9_accuracy: 0.9645 - val_dense_10_accuracy: 0.9742 - val_dense_11_accuracy: 0.9755\n",
            "Epoch 3/15\n",
            "469/469 [==============================] - 29s 62ms/step - loss: 1.9604 - dense_7_loss: 0.4723 - dense_8_loss: 0.4539 - dense_9_loss: 0.4301 - dense_10_loss: 0.3567 - dense_11_loss: 0.2474 - dense_7_accuracy: 0.8422 - dense_8_accuracy: 0.8471 - dense_9_accuracy: 0.8561 - dense_10_accuracy: 0.8807 - dense_11_accuracy: 0.9184 - val_loss: 0.5829 - val_dense_7_loss: 0.1366 - val_dense_8_loss: 0.1286 - val_dense_9_loss: 0.1265 - val_dense_10_loss: 0.0969 - val_dense_11_loss: 0.0942 - val_dense_7_accuracy: 0.9663 - val_dense_8_accuracy: 0.9710 - val_dense_9_accuracy: 0.9721 - val_dense_10_accuracy: 0.9816 - val_dense_11_accuracy: 0.9798\n",
            "Epoch 4/15\n",
            "469/469 [==============================] - 28s 61ms/step - loss: 1.7495 - dense_7_loss: 0.4145 - dense_8_loss: 0.3974 - dense_9_loss: 0.3864 - dense_10_loss: 0.3228 - dense_11_loss: 0.2284 - dense_7_accuracy: 0.8611 - dense_8_accuracy: 0.8669 - dense_9_accuracy: 0.8698 - dense_10_accuracy: 0.8906 - dense_11_accuracy: 0.9225 - val_loss: 0.5162 - val_dense_7_loss: 0.1190 - val_dense_8_loss: 0.1066 - val_dense_9_loss: 0.1120 - val_dense_10_loss: 0.0840 - val_dense_11_loss: 0.0946 - val_dense_7_accuracy: 0.9684 - val_dense_8_accuracy: 0.9743 - val_dense_9_accuracy: 0.9740 - val_dense_10_accuracy: 0.9808 - val_dense_11_accuracy: 0.9758\n",
            "Epoch 5/15\n",
            "469/469 [==============================] - 28s 61ms/step - loss: 1.5900 - dense_7_loss: 0.3712 - dense_8_loss: 0.3605 - dense_9_loss: 0.3493 - dense_10_loss: 0.2941 - dense_11_loss: 0.2149 - dense_7_accuracy: 0.8742 - dense_8_accuracy: 0.8777 - dense_9_accuracy: 0.8805 - dense_10_accuracy: 0.8997 - dense_11_accuracy: 0.9264 - val_loss: 0.4366 - val_dense_7_loss: 0.1025 - val_dense_8_loss: 0.0925 - val_dense_9_loss: 0.0983 - val_dense_10_loss: 0.0694 - val_dense_11_loss: 0.0740 - val_dense_7_accuracy: 0.9723 - val_dense_8_accuracy: 0.9760 - val_dense_9_accuracy: 0.9757 - val_dense_10_accuracy: 0.9820 - val_dense_11_accuracy: 0.9810\n",
            "Epoch 6/15\n",
            "469/469 [==============================] - 29s 61ms/step - loss: 1.4579 - dense_7_loss: 0.3383 - dense_8_loss: 0.3262 - dense_9_loss: 0.3234 - dense_10_loss: 0.2744 - dense_11_loss: 0.1955 - dense_7_accuracy: 0.8843 - dense_8_accuracy: 0.8887 - dense_9_accuracy: 0.8899 - dense_10_accuracy: 0.9054 - dense_11_accuracy: 0.9326 - val_loss: 0.4142 - val_dense_7_loss: 0.0952 - val_dense_8_loss: 0.0880 - val_dense_9_loss: 0.0942 - val_dense_10_loss: 0.0654 - val_dense_11_loss: 0.0713 - val_dense_7_accuracy: 0.9758 - val_dense_8_accuracy: 0.9771 - val_dense_9_accuracy: 0.9771 - val_dense_10_accuracy: 0.9846 - val_dense_11_accuracy: 0.9834\n",
            "Epoch 7/15\n",
            "469/469 [==============================] - 29s 62ms/step - loss: 1.3372 - dense_7_loss: 0.3077 - dense_8_loss: 0.2991 - dense_9_loss: 0.2926 - dense_10_loss: 0.2508 - dense_11_loss: 0.1870 - dense_7_accuracy: 0.8949 - dense_8_accuracy: 0.8971 - dense_9_accuracy: 0.8983 - dense_10_accuracy: 0.9128 - dense_11_accuracy: 0.9349 - val_loss: 0.3756 - val_dense_7_loss: 0.0876 - val_dense_8_loss: 0.0783 - val_dense_9_loss: 0.0875 - val_dense_10_loss: 0.0568 - val_dense_11_loss: 0.0654 - val_dense_7_accuracy: 0.9753 - val_dense_8_accuracy: 0.9785 - val_dense_9_accuracy: 0.9765 - val_dense_10_accuracy: 0.9859 - val_dense_11_accuracy: 0.9835\n",
            "Epoch 8/15\n",
            "469/469 [==============================] - 29s 62ms/step - loss: 1.2542 - dense_7_loss: 0.2892 - dense_8_loss: 0.2774 - dense_9_loss: 0.2743 - dense_10_loss: 0.2368 - dense_11_loss: 0.1765 - dense_7_accuracy: 0.8994 - dense_8_accuracy: 0.9032 - dense_9_accuracy: 0.9035 - dense_10_accuracy: 0.9157 - dense_11_accuracy: 0.9376 - val_loss: 0.3646 - val_dense_7_loss: 0.0856 - val_dense_8_loss: 0.0753 - val_dense_9_loss: 0.0815 - val_dense_10_loss: 0.0540 - val_dense_11_loss: 0.0681 - val_dense_7_accuracy: 0.9753 - val_dense_8_accuracy: 0.9794 - val_dense_9_accuracy: 0.9789 - val_dense_10_accuracy: 0.9863 - val_dense_11_accuracy: 0.9828\n",
            "Epoch 9/15\n",
            "469/469 [==============================] - 29s 62ms/step - loss: 1.1696 - dense_7_loss: 0.2702 - dense_8_loss: 0.2573 - dense_9_loss: 0.2557 - dense_10_loss: 0.2212 - dense_11_loss: 0.1653 - dense_7_accuracy: 0.9059 - dense_8_accuracy: 0.9093 - dense_9_accuracy: 0.9085 - dense_10_accuracy: 0.9221 - dense_11_accuracy: 0.9412 - val_loss: 0.3445 - val_dense_7_loss: 0.0795 - val_dense_8_loss: 0.0707 - val_dense_9_loss: 0.0805 - val_dense_10_loss: 0.0539 - val_dense_11_loss: 0.0600 - val_dense_7_accuracy: 0.9788 - val_dense_8_accuracy: 0.9804 - val_dense_9_accuracy: 0.9770 - val_dense_10_accuracy: 0.9861 - val_dense_11_accuracy: 0.9849\n",
            "Epoch 10/15\n",
            "469/469 [==============================] - 30s 64ms/step - loss: 1.1089 - dense_7_loss: 0.2549 - dense_8_loss: 0.2443 - dense_9_loss: 0.2397 - dense_10_loss: 0.2102 - dense_11_loss: 0.1597 - dense_7_accuracy: 0.9085 - dense_8_accuracy: 0.9130 - dense_9_accuracy: 0.9135 - dense_10_accuracy: 0.9245 - dense_11_accuracy: 0.9438 - val_loss: 0.3221 - val_dense_7_loss: 0.0756 - val_dense_8_loss: 0.0653 - val_dense_9_loss: 0.0738 - val_dense_10_loss: 0.0458 - val_dense_11_loss: 0.0616 - val_dense_7_accuracy: 0.9785 - val_dense_8_accuracy: 0.9812 - val_dense_9_accuracy: 0.9800 - val_dense_10_accuracy: 0.9883 - val_dense_11_accuracy: 0.9849\n",
            "Epoch 11/15\n",
            "469/469 [==============================] - 30s 64ms/step - loss: 1.0536 - dense_7_loss: 0.2386 - dense_8_loss: 0.2353 - dense_9_loss: 0.2245 - dense_10_loss: 0.2016 - dense_11_loss: 0.1536 - dense_7_accuracy: 0.9155 - dense_8_accuracy: 0.9147 - dense_9_accuracy: 0.9198 - dense_10_accuracy: 0.9275 - dense_11_accuracy: 0.9444 - val_loss: 0.3170 - val_dense_7_loss: 0.0682 - val_dense_8_loss: 0.0664 - val_dense_9_loss: 0.0754 - val_dense_10_loss: 0.0466 - val_dense_11_loss: 0.0603 - val_dense_7_accuracy: 0.9805 - val_dense_8_accuracy: 0.9817 - val_dense_9_accuracy: 0.9799 - val_dense_10_accuracy: 0.9872 - val_dense_11_accuracy: 0.9860\n",
            "Epoch 12/15\n",
            "469/469 [==============================] - 29s 62ms/step - loss: 0.9971 - dense_7_loss: 0.2267 - dense_8_loss: 0.2219 - dense_9_loss: 0.2158 - dense_10_loss: 0.1919 - dense_11_loss: 0.1408 - dense_7_accuracy: 0.9189 - dense_8_accuracy: 0.9194 - dense_9_accuracy: 0.9211 - dense_10_accuracy: 0.9301 - dense_11_accuracy: 0.9491 - val_loss: 0.3116 - val_dense_7_loss: 0.0665 - val_dense_8_loss: 0.0619 - val_dense_9_loss: 0.0721 - val_dense_10_loss: 0.0458 - val_dense_11_loss: 0.0653 - val_dense_7_accuracy: 0.9802 - val_dense_8_accuracy: 0.9828 - val_dense_9_accuracy: 0.9796 - val_dense_10_accuracy: 0.9878 - val_dense_11_accuracy: 0.9840\n",
            "Epoch 13/15\n",
            "469/469 [==============================] - 29s 63ms/step - loss: 0.9491 - dense_7_loss: 0.2196 - dense_8_loss: 0.2096 - dense_9_loss: 0.2015 - dense_10_loss: 0.1815 - dense_11_loss: 0.1369 - dense_7_accuracy: 0.9207 - dense_8_accuracy: 0.9244 - dense_9_accuracy: 0.9281 - dense_10_accuracy: 0.9335 - dense_11_accuracy: 0.9510 - val_loss: 0.3090 - val_dense_7_loss: 0.0677 - val_dense_8_loss: 0.0614 - val_dense_9_loss: 0.0712 - val_dense_10_loss: 0.0462 - val_dense_11_loss: 0.0625 - val_dense_7_accuracy: 0.9807 - val_dense_8_accuracy: 0.9828 - val_dense_9_accuracy: 0.9812 - val_dense_10_accuracy: 0.9876 - val_dense_11_accuracy: 0.9855\n",
            "Epoch 14/15\n",
            "469/469 [==============================] - 29s 63ms/step - loss: 0.9214 - dense_7_loss: 0.2112 - dense_8_loss: 0.2054 - dense_9_loss: 0.1974 - dense_10_loss: 0.1768 - dense_11_loss: 0.1306 - dense_7_accuracy: 0.9228 - dense_8_accuracy: 0.9248 - dense_9_accuracy: 0.9274 - dense_10_accuracy: 0.9360 - dense_11_accuracy: 0.9526 - val_loss: 0.2945 - val_dense_7_loss: 0.0642 - val_dense_8_loss: 0.0579 - val_dense_9_loss: 0.0726 - val_dense_10_loss: 0.0402 - val_dense_11_loss: 0.0596 - val_dense_7_accuracy: 0.9815 - val_dense_8_accuracy: 0.9830 - val_dense_9_accuracy: 0.9811 - val_dense_10_accuracy: 0.9898 - val_dense_11_accuracy: 0.9865\n",
            "Epoch 15/15\n",
            "469/469 [==============================] - 29s 62ms/step - loss: 0.8860 - dense_7_loss: 0.2007 - dense_8_loss: 0.1961 - dense_9_loss: 0.1894 - dense_10_loss: 0.1742 - dense_11_loss: 0.1256 - dense_7_accuracy: 0.9259 - dense_8_accuracy: 0.9273 - dense_9_accuracy: 0.9294 - dense_10_accuracy: 0.9358 - dense_11_accuracy: 0.9540 - val_loss: 0.2878 - val_dense_7_loss: 0.0660 - val_dense_8_loss: 0.0557 - val_dense_9_loss: 0.0706 - val_dense_10_loss: 0.0404 - val_dense_11_loss: 0.0550 - val_dense_7_accuracy: 0.9812 - val_dense_8_accuracy: 0.9849 - val_dense_9_accuracy: 0.9810 - val_dense_10_accuracy: 0.9889 - val_dense_11_accuracy: 0.9868\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f03382cf090>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "w1gl0EeoPo6k"
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k8gkvmbWLoY1"
      },
      "cell_type": "markdown",
      "source": [
        "## Calculate Accuracy\n",
        "Custom accuracy calculation for individual digits and the whole sequence."
      ]
    },
    {
      "metadata": {
        "id": "UHb7NM2sQZ3U"
      },
      "cell_type": "code",
      "source": [
        "def calculate_acc(predictions,real_labels):\n",
        "    \n",
        "    individual_counter = 0\n",
        "    global_sequence_counter = 0\n",
        "    for i in range(0,len(predictions[0])):\n",
        "        # Reset sequence counter at the start of each image\n",
        "        sequence_counter = 0 \n",
        "        \n",
        "        for j in range(0,5):\n",
        "            if np.argmax(predictions[j][i]) == np.argmax(real_labels[j][i]):\n",
        "                individual_counter += 1\n",
        "                sequence_counter += 1\n",
        "        \n",
        "        if sequence_counter == 5:\n",
        "            global_sequence_counter += 1\n",
        "         \n",
        "    ind_accuracy = individual_counter/50000.0\n",
        "    global_accuracy = global_sequence_counter/10000.0\n",
        "    \n",
        "    return ind_accuracy,global_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LZSUiAerQ7tq"
      },
      "cell_type": "code",
      "source": [
        "ind_acc, glob_acc = calculate_acc(predictions, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_I57NhTmRu2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4adaff67-059b-4163-b6b7-d87d2a671376"
      },
      "cell_type": "code",
      "source": [
        "print(\"The individual accuracy is {} %\".format(ind_acc * 100))\n",
        "print(\"The sequence prediction accuracy is {} %\".format(glob_acc * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The individual accuracy is 98.456 %\n",
            "The sequence prediction accuracy is 92.73 %\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "TI7q72qiR49W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c5e1ea-4d82-4c2b-ebfb-d66da8c55ac1"
      },
      "cell_type": "code",
      "source": [
        "# Printing some examples of real and predicted labels\n",
        "for i in random.sample(range(0,4),4):\n",
        "    \n",
        "    actual_labels = []\n",
        "    predicted_labels = []\n",
        "    \n",
        "    for j in range(0,5):\n",
        "        actual_labels.append(np.argmax(test_labels[j][i]))\n",
        "        predicted_labels.append(np.argmax(predictions[j][i]))\n",
        "        \n",
        "    print(\"Actual labels: {}\".format(actual_labels))\n",
        "    print(\"Predicted labels: {}\\n\".format(predicted_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual labels: [9, 6, 9, 10, 10]\n",
            "Predicted labels: [9, 6, 9, 10, 10]\n",
            "\n",
            "Actual labels: [6, 8, 1, 0, 2]\n",
            "Predicted labels: [6, 8, 1, 0, 2]\n",
            "\n",
            "Actual labels: [2, 7, 0, 0, 8]\n",
            "Predicted labels: [2, 7, 0, 0, 8]\n",
            "\n",
            "Actual labels: [0, 0, 7, 4, 10]\n",
            "Predicted labels: [0, 0, 7, 4, 10]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJEi3u2n8Zj6",
        "outputId": "ac3cf1b1-dbb0-4c79-8b34-8684546fc028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[9.9930131e-01, 6.4032252e-10, 1.7917901e-07, ..., 5.9688051e-04,\n",
            "        9.9530465e-05, 2.3554102e-16],\n",
            "       [2.1038360e-08, 2.9904782e-03, 9.8883957e-01, ..., 1.3432149e-05,\n",
            "        1.3222046e-07, 9.1998654e-14],\n",
            "       [1.0442943e-06, 2.2672614e-08, 4.3847699e-09, ..., 4.5617884e-03,\n",
            "        2.1824244e-02, 5.1579474e-12],\n",
            "       ...,\n",
            "       [2.1125283e-14, 9.9999833e-01, 1.0846008e-10, ..., 4.7516511e-09,\n",
            "        3.5110734e-09, 1.4635922e-19],\n",
            "       [4.2228594e-09, 2.8338759e-06, 4.4741034e-07, ..., 3.8888751e-04,\n",
            "        1.6967483e-01, 1.6501025e-14],\n",
            "       [4.7704662e-10, 6.3338657e-13, 3.0530075e-12, ..., 5.2161049e-06,\n",
            "        9.9996436e-01, 2.9880423e-15]], dtype=float32), array([[9.99990106e-01, 3.83150525e-11, 1.20728818e-12, ...,\n",
            "        7.68103200e-06, 8.00316229e-07, 8.36732077e-23],\n",
            "       [3.19842275e-06, 4.91138897e-04, 8.62071756e-04, ...,\n",
            "        5.49578835e-05, 1.00829075e-05, 1.48922373e-22],\n",
            "       [1.16842653e-04, 3.84080012e-09, 1.53115555e-03, ...,\n",
            "        9.98263299e-01, 1.46075108e-05, 9.67658256e-21],\n",
            "       ...,\n",
            "       [9.90943777e-14, 9.99995708e-01, 7.21916624e-11, ...,\n",
            "        1.04737372e-10, 1.63856495e-09, 1.60841847e-08],\n",
            "       [2.67251398e-05, 1.41619559e-04, 9.99784887e-01, ...,\n",
            "        9.46069486e-06, 2.32656490e-08, 4.61009234e-27],\n",
            "       [2.51899768e-09, 7.72532076e-06, 1.65891412e-09, ...,\n",
            "        5.06093260e-04, 6.58227014e-04, 5.21373760e-17]], dtype=float32), array([[2.2334288e-09, 5.2141911e-07, 1.5213231e-10, ..., 5.5439194e-14,\n",
            "        6.5698885e-08, 7.3983199e-18],\n",
            "       [9.9797064e-01, 1.5267275e-03, 2.6276385e-07, ..., 8.3240069e-05,\n",
            "        2.2527801e-04, 5.8814946e-14],\n",
            "       [2.2783406e-09, 9.7010428e-01, 5.7386642e-06, ..., 4.2499360e-06,\n",
            "        3.0122348e-07, 1.6790178e-12],\n",
            "       ...,\n",
            "       [7.8452895e-12, 1.8683614e-06, 3.7232425e-10, ..., 1.1651761e-11,\n",
            "        1.8277979e-10, 9.9999809e-01],\n",
            "       [5.2935946e-12, 2.3402366e-07, 1.2758596e-14, ..., 4.3559892e-11,\n",
            "        3.9252219e-09, 2.8911293e-26],\n",
            "       [1.6377724e-08, 4.6981970e-04, 9.5535526e-09, ..., 1.1970990e-07,\n",
            "        9.5358622e-08, 3.2673731e-15]], dtype=float32), array([[1.7705077e-06, 4.6247416e-04, 4.6703103e-06, ..., 8.8279245e-07,\n",
            "        1.6404821e-03, 2.0177133e-09],\n",
            "       [9.9996138e-01, 2.6004523e-09, 2.7326407e-06, ..., 1.3161220e-05,\n",
            "        4.3952980e-07, 9.3970533e-11],\n",
            "       [9.4732678e-01, 1.7301437e-08, 2.1422550e-02, ..., 2.6021753e-02,\n",
            "        2.4698663e-03, 5.7978091e-13],\n",
            "       ...,\n",
            "       [9.9908820e-17, 4.8119806e-17, 1.5810127e-10, ..., 5.6413674e-13,\n",
            "        3.4663575e-20, 1.0000000e+00],\n",
            "       [3.5170309e-09, 9.9990463e-01, 1.4040917e-06, ..., 9.2535862e-05,\n",
            "        1.7440461e-11, 2.3404672e-13],\n",
            "       [8.2799525e-06, 2.1404749e-09, 2.4940125e-03, ..., 9.9749327e-01,\n",
            "        6.3471273e-10, 4.0354626e-11]], dtype=float32), array([[1.0323920e-17, 1.2138038e-13, 5.7950008e-16, ..., 7.7336352e-13,\n",
            "        3.0030072e-13, 1.0000000e+00],\n",
            "       [5.8230333e-04, 1.4398593e-04, 6.3948361e-03, ..., 9.6785116e-01,\n",
            "        1.5939279e-04, 2.3154240e-02],\n",
            "       [6.0519994e-07, 3.3557303e-06, 9.9700052e-01, ..., 1.3734502e-05,\n",
            "        5.0977892e-08, 2.9757826e-03],\n",
            "       ...,\n",
            "       [6.1611082e-22, 9.6014544e-20, 2.6248227e-19, ..., 5.0112825e-20,\n",
            "        1.5763303e-18, 1.0000000e+00],\n",
            "       [5.2984799e-08, 7.5270299e-07, 9.4288447e-07, ..., 1.2261423e-03,\n",
            "        7.4675792e-01, 2.1932616e-03],\n",
            "       [9.8859030e-01, 1.0555988e-09, 4.5793118e-07, ..., 1.7677778e-06,\n",
            "        3.9574068e-05, 1.1360118e-02]], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6BAwhIZqSZG8"
      },
      "cell_type": "markdown",
      "source": [
        "Source: https://sajalsharma.com/portfolio/digit_sequence_recognition"
      ]
    },
    {
      "metadata": {
        "id": "W5DAKHvTpQ-B"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualize Data\n",
        "Check the distribution of the labels to see what kind of data the MNIST dataset contains."
      ]
    },
    {
      "metadata": {
        "id": "EHd2PnBvZ524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "8509daea-72b8-4e39-a854-2bacf22113e9"
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "flat_test = [item for sublist in y_synth_test for item in sublist]\n",
        "flat_train = [item for sublist in y_synth_train for item in sublist]\n",
        "\n",
        "\n",
        "train_num_length = Counter(flat_train)\n",
        "test_num_length = Counter(flat_test)\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.subplot(251)\n",
        "plt.bar(train_num_length.keys(), train_num_length.values(), align='center')\n",
        "plt.title('Train')\n",
        "plt.xlabel('Length')\n",
        "\n",
        "plt.subplot(253)\n",
        "plt.bar(test_num_length.keys(), test_num_length.values(), align='center')\n",
        "plt.title('Test')\n",
        "plt.xlabel('Length')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Length')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "e0cjub4Vi-j8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "330531e2-b0ff-4261-cb40-f1b456ff0a53"
      },
      "cell_type": "code",
      "source": [
        "flat_test_reduced = []\n",
        "flat_train_reduced = []\n",
        "for sublist in y_synth_test:\n",
        "    for item in sublist:\n",
        "      if item is not 10:\n",
        "        flat_test_reduced.append(item)\n",
        "        \n",
        "for sublist in y_synth_train:\n",
        "    for item in sublist:\n",
        "      if item is not 10:\n",
        "        flat_train_reduced.append(item)\n",
        "        \n",
        "\n",
        "\n",
        "train_num_length_reduced = Counter(flat_train_reduced)\n",
        "test_num_length_reduced = Counter(flat_test_reduced)\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))\n",
        "\n",
        "\n",
        "ax1.bar(train_num_length_reduced.keys(), train_num_length_reduced.values(), align='center')\n",
        "ax1.set_title('Train')\n",
        "ax1.set_xlabel('Length')\n",
        "\n",
        "ax2.bar(test_num_length_reduced.keys(), test_num_length_reduced.values(), align='center')\n",
        "ax2.set_title('Test')\n",
        "ax2.set_xlabel('Length')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Length')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy "
      ],
      "metadata": {
        "id": "r-5mbhORBJNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyiulBuItGz4",
        "outputId": "704b0f4f-e807-43a5-db5b-c2c1153d8c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = tempfile.gettempdir()"
      ],
      "metadata": {
        "id": "YtxC8_lL47Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RopFtABk8Jwt",
        "outputId": "4ebf03a0-4c76-4948-e70e-d86aa59ee2fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/tmp'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "version = 1 "
      ],
      "metadata": {
        "id": "rDUnklYOLEre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's join the temp model directory with our chosen version number \n",
        "# The expected result will be = '\\tmp\\version number'\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "print('export_path = {}\\n'.format(export_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3BFgjZZLF1d",
        "outputId": "c31b0072-d358-49ea-8733-37bbb516abc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "export_path = /tmp/1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's save the model using simple_save\n",
        "# If the directory already exists, we will remove it using '!rm' \n",
        "# rm removes each file specified on the command line. \n",
        "\n",
        "if os.path.isdir(export_path):\n",
        "  print('\\nAlready saved a model, cleaning up\\n')\n",
        "  !rm -r {export_path}\n",
        "\n",
        "model.save(\n",
        "    export_path,)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8eTxHjBLIfc",
        "outputId": "780009ab-594e-4f01-c834-5ab4f9c50d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l {export_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9Ra026TLWhb",
        "outputId": "33ff75ae-91d7-47b3-c030-99ca016b0dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 296\n",
            "drwxr-xr-x 2 root root   4096 Apr 25 19:22 assets\n",
            "-rw-r--r-- 1 root root  30105 Apr 25 19:22 keras_metadata.pb\n",
            "-rw-r--r-- 1 root root 259561 Apr 25 19:22 saved_model.pb\n",
            "drwxr-xr-x 2 root root   4096 Apr 25 19:22 variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can view our saved model\n",
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb9qG73HLg93",
        "outputId": "b672a915-35ba-4e68-dd23-fb650faf8e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['input_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 64, 64, 1)\n",
            "        name: serving_default_input_2:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_10'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 11)\n",
            "        name: StatefulPartitionedCall:0\n",
            "    outputs['dense_11'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 11)\n",
            "        name: StatefulPartitionedCall:1\n",
            "    outputs['dense_7'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 11)\n",
            "        name: StatefulPartitionedCall:2\n",
            "    outputs['dense_8'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 11)\n",
            "        name: StatefulPartitionedCall:3\n",
            "    outputs['dense_9'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 11)\n",
            "        name: StatefulPartitionedCall:4\n",
            "  Method name is: tensorflow/serving/predict\n",
            "\n",
            "Concrete Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='input_2')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32, name='input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY2-ep-pLsse",
        "outputId": "993fbe8f-1c80-43c5-afc9-9d62a0e87252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2943  100  2943    0     0  60061      0 --:--:-- --:--:-- --:--:-- 58860\n",
            "OK\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:12 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [349 B]\n",
            "Get:13 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [341 B]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,272 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,167 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [942 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,949 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [909 kB]\n",
            "Get:24 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,732 kB]\n",
            "Get:25 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,496 kB]\n",
            "Get:26 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [999 kB]\n",
            "Get:27 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 14.8 MB in 4s (3,357 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "56 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tensorflow-model-server"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX71bSEuLyak",
        "outputId": "c1b9b215-a08d-4992-ef88-30f471f9afc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 56 not upgraded.\n",
            "Need to get 340 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.8.0 [340 MB]\n",
            "Fetched 340 MB in 7s (50.6 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 155501 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.8.0_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.8.0) ...\n",
            "Setting up tensorflow-model-server (2.8.0) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "metadata": {
        "id": "PGoe5nMEL3k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=fashion_model \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMIOAJodL8pQ",
        "outputId": "388f4275-00aa-4d58-ed68-7b62c057dceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail server.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ltm3oB3L_J1",
        "outputId": "b49ea166-0406-4be0-f60e-f6d6f54d1ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show(idx, title):\n",
        "  plt.figure()\n",
        "  plt.imshow(X_test[idx].reshape(64,64))\n",
        "  plt.title('\\n\\n{}'.format(title), fontdict={'size': 16})\n"
      ],
      "metadata": {
        "id": "wWho2dRTMAwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rando = random.randint(0,len(X_test)-1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "y-kA7UOPMIUX",
        "outputId": "17aa4782-647e-47d5-b8e6-3644077c116d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-428bd40d329d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrando\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrando\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'An Example Image: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrando\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-63-1baee20ea6b8>\u001b[0m in \u001b[0;36mshow\u001b[0;34m(idx, title)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (64,64)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "av6aKl1xMIZQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}